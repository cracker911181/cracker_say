
# Coded by Cracker
# CRACKER911181
 
 
import marshal
exec(marshal.loads(b'\xe3\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x00\x00\x00@\x00\x00\x00sL\x00\x00\x00d\x00d\x01l\x00Z\x00d\x02d\x03\x84\x00Z\x01d\x04d\x05\x84\x00Z\x02d\x00d\x01l\x00Z\x00d\x06Z\x03d\x07Z\x04d\x08Z\x05d\tZ\x06d\nZ\x07d\x0bZ\x08d\x0cZ\td\rZ\nd\x0ed\x0f\x84\x00Z\x0bd\x01S\x00)\x10\xe9\x00\x00\x00\x00Nc\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x12\x00\x00\x00\x04\x00\x00\x00C\x00\x00\x00s\x04\x01\x00\x00g\x00}\x01g\x00}\x02t\x00|\x00\x83\x01}\x03t\x01|\x03d\x01\x17\x00\x83\x01D\x00]\x0e}\x04|\x01\xa0\x02d\x02\xa1\x01\x01\x00q\x1ct\x01|\x03d\x01\x17\x00\x83\x01D\x00]\x0e}\x04|\x02\xa0\x02d\x02\xa1\x01\x01\x00q8t\x03|\x01\x83\x01}\x05t\x03|\x02\x83\x01}\x06|\x05\xa0\x04d\x03d\x04\xa1\x02}\x07|\x07\xa0\x04d\x05d\x04\xa1\x02}\x08|\x08\xa0\x04d\x06d\x04\xa1\x02}\t|\t\xa0\x04d\x07d\x04\xa1\x02}\n|\n\xa0\x04d\x08d\x04\xa1\x02}\x0b|\x06\xa0\x04d\x03d\x04\xa1\x02}\t|\t\xa0\x04d\x05d\x04\xa1\x02}\x0c|\x0c\xa0\x04d\x06d\x04\xa1\x02}\r|\r\xa0\x04d\x07d\x04\xa1\x02}\x0e|\x0e\xa0\x04d\x08d\x04\xa1\x02}\x0ft\x03d\x08|\x0b\x17\x00d\t\x17\x00|\x00\x17\x00d\n\x17\x00|\x0f\x17\x00\x83\x01}\x10d\x0b|\x10\x17\x00d\x0c\x17\x00}\x11t\x05|\x11\x83\x01\x01\x00d\x00S\x00)\rN\xe9\x02\x00\x00\x00\xfa\x01=\xfa\x01\'\xda\x00\xfa\x01,\xfa\x01[\xfa\x01]\xfa\x01 \xfa\x04\n | \xfa\x05 |\n  \xfa\x03\n\n z\xa1\n         \\   \n          \\\n             ^__^ \n             (oo)\\_______\n             (__)\\       )\\/\\ \n                 ||----w |\n                 ||     ||\n    )\x06\xda\x03len\xda\x05range\xda\x06append\xda\x03str\xda\x07replace\xda\x05print)\x12\xda\x04spch\xda\x04set1\xda\x04set2\xda\x02ln\xda\x01f\xda\x02xc\xda\x03xc1\xda\x02xx\xda\x03xx1\xda\x03xx2\xda\x03xx3\xda\x03xx4\xda\x04xx21\xda\x04xx22\xda\x04xx23\xda\x04xx24\xda\x05spech\xda\x03cow\xa9\x00r%\x00\x00\x00\xe1\xb8\x01\x00\x00 \x1b[91m Contact With Owner\n \x1b[93m \n\n   |===================================================|\n   |                   OWNER INFO                      |\n   |===================================================|\n   | Facebook | https://www.facebook.com/cracker911181 |\n   | Telegram | https://t.me/cracker911181             |\n   | GitHub   | https://github.com/cracker911181       |\n   |==========|========================================| \x1b[00m\nr$\x00\x00\x00\x03\x00\x00\x00s4\x00\x00\x00\x00\x02\x04\x01\x04\x04\x08\x01\x10\x01\x0c\x01\x10\x02\x0c\x03\x08\x01\x08\x02\x0c\x01\x0c\x01\x0c\x01\x0c\x01\x0c\x03\x0c\x01\x0c\x01\x0c\x01\x0c\x01\x0c\x02\x1c\x03\x02\x01\x02\xff\x02\x01\x02\xff\x04\x0br$\x00\x00\x00c\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x13\x00\x00\x00\x04\x00\x00\x00C\x00\x00\x00s\x1c\x01\x00\x00d\x01d\x00l\x00}\x01g\x00}\x02g\x00}\x03t\x01|\x00\x83\x01}\x04t\x02|\x04d\x02\x17\x00\x83\x01D\x00]\x0e}\x05|\x02\xa0\x03d\x03\xa1\x01\x01\x00q$t\x02|\x04d\x02\x17\x00\x83\x01D\x00]\x0e}\x05|\x03\xa0\x03d\x03\xa1\x01\x01\x00q@t\x04|\x02\x83\x01}\x06t\x04|\x03\x83\x01}\x07|\x06\xa0\x05d\x04d\x05\xa1\x02}\x08|\x08\xa0\x05d\x06d\x05\xa1\x02}\t|\t\xa0\x05d\x07d\x05\xa1\x02}\n|\n\xa0\x05d\x08d\x05\xa1\x02}\x0b|\x0b\xa0\x05d\td\x05\xa1\x02}\x0c|\x07\xa0\x05d\x04d\x05\xa1\x02}\n|\n\xa0\x05d\x06d\x05\xa1\x02}\r|\r\xa0\x05d\x07d\x05\xa1\x02}\x0e|\x0e\xa0\x05d\x08d\x05\xa1\x02}\x0f|\x0f\xa0\x05d\td\x05\xa1\x02}\x10t\x04d\t|\x0c\x17\x00d\n\x17\x00|\x00\x17\x00d\x0b\x17\x00|\x10\x17\x00\x83\x01}\x11d\x0c|\x0c\x17\x00d\r\x17\x00|\x00\x17\x00d\x0e\x17\x00|\x10\x17\x00d\x0f\x17\x00}\x12t\x06|\x12\x83\x01\x01\x00d\x00S\x00)\x10Nr\x01\x00\x00\x00r\x02\x00\x00\x00r\x03\x00\x00\x00r\x04\x00\x00\x00r\x05\x00\x00\x00r\x06\x00\x00\x00r\x07\x00\x00\x00r\x08\x00\x00\x00r\t\x00\x00\x00r\n\x00\x00\x00r\x0b\x00\x00\x00a$\x01\x00\x00\n                        `.         ,-,\n                        ` `.    ,;\' / \n                         `.  ,\'/ .\'\n                          `. X /.\'\n                .-;--\'\'--.._` ` (\n              .\'            /   `\n             ,           ` \'   Q \'\n             ,         ,   `._    \\    u*\x00\x00\x00\n          ,.|         \'     `-.;_\'  \xe2\x86\x92| z* |\n          :  . `  ;    `  ` --,.._;    zw\n           \' `    ,   )   .\'\n              `._ ,  \'   /_\n                 ; ,\'\'-,;\' ``-\n                  ``-..__``--`)\x07\xda\x02osr\r\x00\x00\x00r\x0e\x00\x00\x00r\x0f\x00\x00\x00r\x10\x00\x00\x00r\x11\x00\x00\x00r\x12\x00\x00\x00)\x13r\x13\x00\x00\x00r\'\x00\x00\x00r\x14\x00\x00\x00r\x15\x00\x00\x00r\x16\x00\x00\x00r\x17\x00\x00\x00r\x18\x00\x00\x00r\x19\x00\x00\x00r\x1a\x00\x00\x00r\x1b\x00\x00\x00r\x1c\x00\x00\x00r\x1d\x00\x00\x00r\x1e\x00\x00\x00r\x1f\x00\x00\x00r \x00\x00\x00r!\x00\x00\x00r"\x00\x00\x00r#\x00\x00\x00\xda\x06rabbitr%\x00\x00\x00r%\x00\x00\x00r&\x00\x00\x00r(\x00\x00\x003\x00\x00\x00sF\x00\x00\x00\x00\x01\x08\x02\x04\x01\x04\x04\x08\x01\x10\x01\x0c\x01\x10\x02\x0c\x03\x08\x01\x08\x02\x0c\x01\x0c\x01\x0c\x01\x0c\x01\x0c\x03\x0c\x01\x0c\x01\x0c\x01\x0c\x01\x0c\x02\x1c\x03\x02\x07\x02\xf9\x02\x07\x02\xf9\x02\x08\x02\xf8\x02\x08\x02\xf8\x02\t\x02\xf7\x02\t\x02\xf7\x04\x0er(\x00\x00\x00z\x05\x1b[00mz\x05\x1b[04mz\x05\x1b[92mz\x05\x1b[93mz\x05\x1b[94mz\x05\x1b[95mz\x05\x1b[96mz\x05\x1b[41mc\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x15\x00\x00\x00\x04\x00\x00\x00C\x00\x00\x00s\\\x01\x00\x00g\x00}\x01g\x00}\x02t\x00d\x01t\x00|\x00\x83\x01\x17\x00\x83\x01}\x03t\x01|\x03\x83\x01}\x04t\x02|\x04d\x02\x17\x00\x83\x01D\x00]\x0e}\x05|\x01\xa0\x03d\x03\xa1\x01\x01\x00q,t\x02|\x04d\x02\x17\x00\x83\x01D\x00]\x0e}\x05|\x02\xa0\x03d\x03\xa1\x01\x01\x00qHt\x00|\x01\x83\x01}\x06t\x00|\x02\x83\x01}\x07|\x06\xa0\x04d\x04d\x05\xa1\x02}\x08|\x08\xa0\x04d\x06d\x05\xa1\x02}\t|\t\xa0\x04d\x07d\x05\xa1\x02}\n|\n\xa0\x04d\x08d\x05\xa1\x02}\x0b|\x0b\xa0\x04d\td\x05\xa1\x02}\x0c|\x07\xa0\x04d\x04d\x05\xa1\x02}\n|\n\xa0\x04d\x06d\x05\xa1\x02}\r|\r\xa0\x04d\x07d\x05\xa1\x02}\x0e|\x0e\xa0\x04d\x08d\x05\xa1\x02}\x0f|\x0f\xa0\x04d\td\x05\xa1\x02}\x10d\n}\x11t\x00d\t|\x0c\x17\x00d\x0b\x17\x00|\x03\x17\x00d\x0c\x17\x00|\x10\x17\x00\x83\x01}\x12t\x00d\r|\x11\x17\x00d\x0e\x17\x00\x83\x01}\x13t\x05d\x0f\x17\x00|\x12\x17\x00d\x10\x17\x00t\x06\x17\x00t\x07\x17\x00d\x11\x17\x00t\x06\x17\x00t\x05\x17\x00d\x12\x17\x00t\x08\x17\x00d\x13\x17\x00t\x05\x17\x00d\x14\x17\x00|\x13\x17\x00d\x05\x17\x00}\x14t\t|\x14\x83\x01\x01\x00d\x00S\x00)\x15Nz\x06Hello r\x02\x00\x00\x00r\x03\x00\x00\x00r\x04\x00\x00\x00r\x05\x00\x00\x00r\x06\x00\x00\x00r\x07\x00\x00\x00r\x08\x00\x00\x00r\t\x00\x00\x00z\x11Welcome To Termuxr\n\x00\x00\x00r\x0b\x00\x00\x00z\x1e\t   \t +++++++++++++++++++\n\t\t| z\x1d |\n\t    \t +++++++++++++++++++r\x0c\x00\x00\x00zM\n         /\n        /\n  ,   ----    , \n /             \\ \n((__---,,,---__))   z\x1adeveloped by cracker911181z3\n   (_) O O (_)_________\n      \\ _ /            |\\ zl\n       o_o \\  CRACKER  | \\ \n            \\   _____  |  *\n             |||   WW||| \n             |||     |||\nz\x02\n )\nr\x10\x00\x00\x00r\r\x00\x00\x00r\x0e\x00\x00\x00r\x0f\x00\x00\x00r\x11\x00\x00\x00\xda\x04pest\xda\tcolouroff\xda\x04red1\xda\x06yellowr\x12\x00\x00\x00)\x15Z\x05spchxr\x14\x00\x00\x00r\x15\x00\x00\x00r\x13\x00\x00\x00r\x16\x00\x00\x00r\x17\x00\x00\x00r\x18\x00\x00\x00r\x19\x00\x00\x00r\x1a\x00\x00\x00r\x1b\x00\x00\x00r\x1c\x00\x00\x00r\x1d\x00\x00\x00r\x1e\x00\x00\x00r\x1f\x00\x00\x00r \x00\x00\x00r!\x00\x00\x00r"\x00\x00\x00Z\x05spch1r#\x00\x00\x00Z\x06spech1\xda\x06bennarr%\x00\x00\x00r%\x00\x00\x00r&\x00\x00\x00r-\x00\x00\x00w\x00\x00\x00sj\x00\x00\x00\x00\x02\x04\x01\x04\x02\x10\x01\x08\x01\x10\x01\x0c\x01\x10\x02\x0c\x03\x08\x01\x08\x02\x0c\x01\x0c\x01\x0c\x01\x0c\x01\x0c\x03\x0c\x01\x0c\x01\x0c\x01\x0c\x01\x0c\x02\x04\x02\x1c\x01\x10\x04\x06\x01\x02\xff\x02\x01\x02\xff\x02\x06\x02\xfa\x02\x06\x02\xfa\x02\x06\x02\xfa\x02\x06\x02\xfa\x02\x06\x02\xfa\x02\x06\x02\xfa\x02\x08\x02\xf8\x02\x08\x02\xf8\x02\x0c\x02\xf4\x02\x0c\x02\xf4\x02\r\x02\xf3\x02\r\x02\xf3\x04\x10r-\x00\x00\x00)\x0cr\'\x00\x00\x00r$\x00\x00\x00r(\x00\x00\x00r*\x00\x00\x00Z\x03redZ\x05greenr,\x00\x00\x00Z\x04blueZ\x04rosyr)\x00\x00\x00r+\x00\x00\x00r-\x00\x00\x00r%\x00\x00\x00r%\x00\x00\x00r%\x00\x00\x00r&\x00\x00\x00\xda\x08<module>\x01\x00\x00\x00s\x18\x00\x00\x00\x08\x02\x080\x084\x08\x03\x04\x02\x04\x01\x04\x01\x04\x01\x04\x01\x04\x01\x04\x02\x04\x04'))


from threading import Thread as pool
import urllib.request
import requests
import base64
import sys,os,time

#cracker
#logo():
        #creator:cracker911181
import os
import time
import sys

#text colour()
#creator: CRACKER911181

white = '\33[00m'
red = '\33[91m'
green = '\33[92m'
yellow = '\33[93m'
blue = '\33[94m'
rosy = '\33[95m'
pest = '\33[96m'


link=str(input(rosy+"\nEnter Your Target Website (eg: 'www.google.com'): "))

############################


try:
	print(yellow+"\n      üé≠Connecting To Server...")
	lnk=str("http://"+link+":80")
	requests.get(lnk)
	print(green+"\n       ‚ÄºÔ∏èÔ∏èConnected‚ÄºÔ∏è   Ô∏è")
	pass
except ConnectionResetError:
	print(red+"\n      ‚ùåNot Connected‚ùåÔ∏è   ")
	sys.exit()
except requests.exceptions.ConnectionError:
	print(red+"\n  ‚ö†Try Again With a valid URL‚ö†Ô∏è    Ô∏è")
	sys.exit()
except requests.exceptions.InvalidURL:
	print(red+"\n        üö´URL Not Validüö´   ")
	sys.exit()

print(pest+"\n\n")
suba=open("a_link.txt","r")
subad=suba.read()
ascii_de=subad.encode("ascii") 
decode=base64.b64decode(ascii_de) 
subadmin=decode.decode("ascii")
sp=subadmin.split("\n")




def find0():
	ss=sp[0:7]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(pest+url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find1():
	ss=sp[7:14]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue
		


#############################



def find2():
	ss=sp[14:21]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find3():
	ss=sp[21:28]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find4():
	ss=sp[28:35]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find5():
	ss=sp[35:42]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find6():
	ss=sp[42:49]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find7():
	ss=sp[49:56]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find8():
	ss=sp[56:63]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find9():
	ss=sp[63:70]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find10():
	ss=sp[70:77]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find11():
	ss=sp[77:84]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find12():
	ss=sp[84:91]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find13():
	ss=sp[91:98]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find14():
	ss=sp[98:105]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find15():
	ss=sp[105:112]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find16():
	ss=sp[112:119]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find17():
	ss=sp[119:126]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find18():
	ss=sp[126:133]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find19():
	ss=sp[133:140]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find20():
	ss=sp[140:147]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find21():
	ss=sp[147:154]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find22():
	ss=sp[154:161]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find23():
	ss=sp[161:168]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find24():
	ss=sp[168:175]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find25():
	ss=sp[175:182]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find26():
	ss=sp[182:189]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find27():
	ss=sp[189:196]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find28():
	ss=sp[196:203]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find29():
	ss=sp[203:210]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find30():
	ss=sp[210:217]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find31():
	ss=sp[217:224]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find32():
	ss=sp[224:231]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find33():
	ss=sp[231:238]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find34():
	ss=sp[238:245]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find35():
	ss=sp[245:252]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find36():
	ss=sp[252:259]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find37():
	ss=sp[259:266]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find38():
	ss=sp[266:273]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find39():
	ss=sp[273:280]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find40():
	ss=sp[280:287]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find41():
	ss=sp[287:294]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find42():
	ss=sp[294:301]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find43():
	ss=sp[301:308]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find44():
	ss=sp[308:315]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find45():
	ss=sp[315:322]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find46():
	ss=sp[322:329]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find47():
	ss=sp[329:336]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find48():
	ss=sp[336:343]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find49():
	ss=sp[343:350]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find50():
	ss=sp[350:357]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find51():
	ss=sp[357:364]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find52():
	ss=sp[364:371]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find53():
	ss=sp[371:378]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find54():
	ss=sp[378:385]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find55():
	ss=sp[385:392]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find56():
	ss=sp[392:399]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find57():
	ss=sp[399:406]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find58():
	ss=sp[406:413]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find59():
	ss=sp[413:420]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find60():
	ss=sp[420:427]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find61():
	ss=sp[427:434]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find62():
	ss=sp[434:441]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find63():
	ss=sp[441:448]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find64():
	ss=sp[448:455]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find65():
	ss=sp[455:462]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find66():
	ss=sp[462:469]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find67():
	ss=sp[469:476]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find68():
	ss=sp[476:483]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find69():
	ss=sp[483:490]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find70():
	ss=sp[490:497]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find71():
	ss=sp[497:504]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find72():
	ss=sp[504:511]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find73():
	ss=sp[511:518]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find74():
	ss=sp[518:525]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find75():
	ss=sp[525:532]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find76():
	ss=sp[532:539]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find77():
	ss=sp[539:546]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find78():
	ss=sp[546:553]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find79():
	ss=sp[553:560]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find80():
	ss=sp[560:567]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find81():
	ss=sp[567:574]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find82():
	ss=sp[574:581]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find83():
	ss=sp[581:588]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find84():
	ss=sp[588:595]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find85():
	ss=sp[595:602]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find86():
	ss=sp[602:609]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find87():
	ss=sp[609:616]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find88():
	ss=sp[616:623]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find89():
	ss=sp[623:630]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find90():
	ss=sp[630:637]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find91():
	ss=sp[637:644]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find92():
	ss=sp[644:651]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find93():
	ss=sp[651:658]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find94():
	ss=sp[658:665]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find95():
	ss=sp[665:672]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find96():
	ss=sp[672:679]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find97():
	ss=sp[679:686]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find98():
	ss=sp[686:693]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find99():
	ss=sp[693:700]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find100():
	ss=sp[700:707]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find101():
	ss=sp[707:714]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find102():
	ss=sp[714:721]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find103():
	ss=sp[721:728]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find104():
	ss=sp[728:735]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find105():
	ss=sp[735:742]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find106():
	ss=sp[742:749]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find107():
	ss=sp[749:756]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find108():
	ss=sp[756:763]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find109():
	ss=sp[763:770]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find110():
	ss=sp[770:777]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find111():
	ss=sp[777:784]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find112():
	ss=sp[784:791]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find113():
	ss=sp[791:798]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find114():
	ss=sp[798:805]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find115():
	ss=sp[805:812]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find116():
	ss=sp[812:819]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find117():
	ss=sp[819:826]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find118():
	ss=sp[826:833]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find119():
	ss=sp[833:840]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find120():
	ss=sp[840:847]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find121():
	ss=sp[847:854]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find122():
	ss=sp[854:861]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find123():
	ss=sp[861:868]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find124():
	ss=sp[868:875]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find125():
	ss=sp[875:882]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find126():
	ss=sp[882:889]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find127():
	ss=sp[889:896]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find128():
	ss=sp[896:903]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find129():
	ss=sp[903:910]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find130():
	ss=sp[910:917]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find131():
	ss=sp[917:924]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find132():
	ss=sp[924:931]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find133():
	ss=sp[931:938]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find134():
	ss=sp[938:945]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find135():
	ss=sp[945:952]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find136():
	ss=sp[952:959]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find137():
	ss=sp[959:966]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find138():
	ss=sp[966:973]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find139():
	ss=sp[973:980]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find140():
	ss=sp[980:987]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find141():
	ss=sp[987:994]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find142():
	ss=sp[994:1001]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find143():
	ss=sp[1001:1008]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find144():
	ss=sp[1008:1015]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find145():
	ss=sp[1015:1022]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find146():
	ss=sp[1022:1029]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find147():
	ss=sp[1029:1036]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find148():
	ss=sp[1036:1043]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find149():
	ss=sp[1043:1050]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find150():
	ss=sp[1050:1057]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find151():
	ss=sp[1057:1064]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find152():
	ss=sp[1064:1071]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find153():
	ss=sp[1071:1078]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find154():
	ss=sp[1078:1085]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find155():
	ss=sp[1085:1092]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find156():
	ss=sp[1092:1099]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find157():
	ss=sp[1099:1106]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find158():
	ss=sp[1106:1113]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find159():
	ss=sp[1113:1120]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find160():
	ss=sp[1120:1127]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find161():
	ss=sp[1127:1134]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find162():
	ss=sp[1134:1141]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find163():
	ss=sp[1141:1148]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find164():
	ss=sp[1148:1155]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find165():
	ss=sp[1155:1162]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find166():
	ss=sp[1162:1169]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find167():
	ss=sp[1169:1176]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find168():
	ss=sp[1176:1183]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find169():
	ss=sp[1183:1190]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find170():
	ss=sp[1190:1197]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find171():
	ss=sp[1197:1204]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find172():
	ss=sp[1204:1211]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################



def find173():
	ss=sp[1211:1218]
	for x in ss:
		url=str("http://"+link+"/"+x)
		try:
			urllib.request.urlopen(url)
			print(url)
		except urllib.error.HTTPError:
			continue
		except ConnectionResetError:
			continue
		except urllib.error.URLError:
			continue
		except:
			continue


#############################


def final():

	t0=pool(target=find0)
	t1=pool(target=find1)
	t2=pool(target=find2)
	t3=pool(target=find3)
	t4=pool(target=find4)
	t5=pool(target=find5)
	t6=pool(target=find6)
	t7=pool(target=find7)
	t8=pool(target=find8)
	t9=pool(target=find9)
	t10=pool(target=find10)
	t11=pool(target=find11)
	t12=pool(target=find12)
	t13=pool(target=find13)
	t14=pool(target=find14)
	t15=pool(target=find15)
	t16=pool(target=find16)
	t17=pool(target=find17)
	t18=pool(target=find18)
	t19=pool(target=find19)
	t20=pool(target=find20)
	t21=pool(target=find21)
	t22=pool(target=find22)
	t23=pool(target=find23)
	t24=pool(target=find24)
	t25=pool(target=find25)
	t26=pool(target=find26)
	t27=pool(target=find27)
	t28=pool(target=find28)
	t29=pool(target=find29)
	t30=pool(target=find30)
	t31=pool(target=find31)
	t32=pool(target=find32)
	t33=pool(target=find33)
	t34=pool(target=find34)
	t35=pool(target=find35)
	t36=pool(target=find36)
	t37=pool(target=find37)
	t38=pool(target=find38)
	t39=pool(target=find39)
	t40=pool(target=find40)
	t41=pool(target=find41)
	t42=pool(target=find42)
	t43=pool(target=find43)
	t44=pool(target=find44)
	t45=pool(target=find45)
	t46=pool(target=find46)
	t47=pool(target=find47)
	t48=pool(target=find48)
	t49=pool(target=find49)
	t50=pool(target=find50)
	t51=pool(target=find51)
	t52=pool(target=find52)
	t53=pool(target=find53)
	t54=pool(target=find54)
	t55=pool(target=find55)
	t56=pool(target=find56)
	t57=pool(target=find57)
	t58=pool(target=find58)
	t59=pool(target=find59)
	t60=pool(target=find60)
	t61=pool(target=find61)
	t62=pool(target=find62)
	t63=pool(target=find63)
	t64=pool(target=find64)
	t65=pool(target=find65)
	t66=pool(target=find66)
	t67=pool(target=find67)
	t68=pool(target=find68)
	t69=pool(target=find69)
	t70=pool(target=find70)
	t71=pool(target=find71)
	t72=pool(target=find72)
	t73=pool(target=find73)
	t74=pool(target=find74)
	t75=pool(target=find75)
	t76=pool(target=find76)
	t77=pool(target=find77)
	t78=pool(target=find78)
	t79=pool(target=find79)
	t80=pool(target=find80)
	t81=pool(target=find81)
	t82=pool(target=find82)
	t83=pool(target=find83)
	t84=pool(target=find84)
	t85=pool(target=find85)
	t86=pool(target=find86)
	t87=pool(target=find87)
	t88=pool(target=find88)
	t89=pool(target=find89)
	t90=pool(target=find90)
	t91=pool(target=find91)
	t92=pool(target=find92)
	t93=pool(target=find93)
	t94=pool(target=find94)
	t95=pool(target=find95)
	t96=pool(target=find96)
	t97=pool(target=find97)
	t98=pool(target=find98)
	t99=pool(target=find99)
	t100=pool(target=find100)
	t101=pool(target=find101)
	t102=pool(target=find102)
	t103=pool(target=find103)
	t104=pool(target=find104)
	t105=pool(target=find105)
	t106=pool(target=find106)
	t107=pool(target=find107)
	t108=pool(target=find108)
	t109=pool(target=find109)
	t110=pool(target=find110)
	t111=pool(target=find111)
	t112=pool(target=find112)
	t113=pool(target=find113)
	t114=pool(target=find114)
	t115=pool(target=find115)
	t116=pool(target=find116)
	t117=pool(target=find117)
	t118=pool(target=find118)
	t119=pool(target=find119)
	t120=pool(target=find120)
	t121=pool(target=find121)
	t122=pool(target=find122)
	t123=pool(target=find123)
	t124=pool(target=find124)
	t125=pool(target=find125)
	t126=pool(target=find126)
	t127=pool(target=find127)
	t128=pool(target=find128)
	t129=pool(target=find129)
	t130=pool(target=find130)
	t131=pool(target=find131)
	t132=pool(target=find132)
	t133=pool(target=find133)
	t134=pool(target=find134)
	t135=pool(target=find135)
	t136=pool(target=find136)
	t137=pool(target=find137)
	t138=pool(target=find138)
	t139=pool(target=find139)
	t140=pool(target=find140)
	t141=pool(target=find141)
	t142=pool(target=find142)
	t143=pool(target=find143)
	t144=pool(target=find144)
	t145=pool(target=find145)
	t146=pool(target=find146)
	t147=pool(target=find147)
	t148=pool(target=find148)
	t149=pool(target=find149)
	t150=pool(target=find150)
	t151=pool(target=find151)
	t152=pool(target=find152)
	t153=pool(target=find153)
	t154=pool(target=find154)
	t155=pool(target=find155)
	t156=pool(target=find156)
	t157=pool(target=find157)
	t158=pool(target=find158)
	t159=pool(target=find159)
	t160=pool(target=find160)
	t161=pool(target=find161)
	t162=pool(target=find162)
	t163=pool(target=find163)
	t164=pool(target=find164)
	t165=pool(target=find165)
	t166=pool(target=find166)
	t167=pool(target=find167)
	t168=pool(target=find168)
	t169=pool(target=find169)
	t170=pool(target=find170)
	t171=pool(target=find171)
	t172=pool(target=find172)
	t173=pool(target=find173)
	
	t0.start()
	t1.start()
	t2.start()
	t3.start()
	t4.start()
	t5.start()
	t6.start()
	t7.start()
	t8.start()
	t9.start()
	t10.start()
	t11.start()
	t12.start()
	t13.start()
	t14.start()
	t15.start()
	t16.start()
	t17.start()
	t18.start()
	t19.start()
	t20.start()
	t21.start()
	t22.start()
	t23.start()
	t24.start()
	t25.start()
	t26.start()
	t27.start()
	t28.start()
	t29.start()
	t30.start()
	t31.start()
	t32.start()
	t33.start()
	t34.start()
	t35.start()
	t36.start()
	t37.start()
	t38.start()
	t39.start()
	t40.start()
	t41.start()
	t42.start()
	t43.start()
	t44.start()
	t45.start()
	t46.start()
	t47.start()
	t48.start()
	t49.start()
	t50.start()
	t51.start()
	t52.start()
	t53.start()
	t54.start()
	t55.start()
	t56.start()
	t57.start()
	t58.start()
	t59.start()
	t60.start()
	t61.start()
	t62.start()
	t63.start()
	t64.start()
	t65.start()
	t66.start()
	t67.start()
	t68.start()
	t69.start()
	t70.start()
	t71.start()
	t72.start()
	t73.start()
	t74.start()
	t75.start()
	t76.start()
	t77.start()
	t78.start()
	t79.start()
	t80.start()
	t81.start()
	t82.start()
	t83.start()
	t84.start()
	t85.start()
	t86.start()
	t87.start()
	t88.start()
	t89.start()
	t90.start()
	t91.start()
	t92.start()
	t93.start()
	t94.start()
	t95.start()
	t96.start()
	t97.start()
	t98.start()
	t99.start()
	t100.start()
	t101.start()
	t102.start()
	t103.start()
	t104.start()
	t105.start()
	t106.start()
	t107.start()
	t108.start()
	t109.start()
	t110.start()
	t111.start()
	t112.start()
	t113.start()
	t114.start()
	t115.start()
	t116.start()
	t117.start()
	t118.start()
	t119.start()
	t120.start()
	t121.start()
	t122.start()
	t123.start()
	t124.start()
	t125.start()
	t126.start()
	t127.start()
	t128.start()
	t129.start()
	t130.start()
	t131.start()
	t132.start()
	t133.start()
	t134.start()
	t135.start()
	t136.start()
	t137.start()
	t138.start()
	t139.start()
	t140.start()
	t141.start()
	t142.start()
	t143.start()
	t144.start()
	t145.start()
	t146.start()
	t147.start()
	t148.start()
	t149.start()
	t150.start()
	t151.start()
	t152.start()
	t153.start()
	t154.start()
	t155.start()
	t156.start()
	t157.start()
	t158.start()
	t159.start()
	t160.start()
	t161.start()
	t162.start()
	t163.start()
	t164.start()
	t165.start()
	t166.start()
	t167.start()
	t168.start()
	t169.start()
	t170.start()
	t171.start()
	t172.start()
	t173.start()


